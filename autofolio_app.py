import streamlit as st
import time
import pandas as pd

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="AutoFolio | AI ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±",
    page_icon="âœ¨",
    layout="centered",
)

# --- ë”ë¯¸ ë°ì´í„° ---
# 1. ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„° (ì‹¤ì œë¡œëŠ” DBë‚˜ ì—°ë™ í”Œë«í¼ì—ì„œ ê°€ì ¸ì˜´)
DUMMY_USER_PROFILE = {
    "name": "í™ê¸¸ë™",
    "skills": ['Python', 'PyTorch', 'TensorFlow', 'LLM', 'Data Analysis', 'React', 'Node.js', 'Figma', 'SQL'],
    "projects": [
        {
            "title": 'ì†Œì…œ ë¯¸ë””ì–´ ê°ì„± ë¶„ì„ ëª¨ë¸',
            "description": 'LSTM ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì†Œì…œ ë¯¸ë””ì–´ í…ìŠ¤íŠ¸ì˜ ê¸ì •/ë¶€ì •ì„ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ í•™ìŠµ, í‰ê°€ê¹Œì§€ ì „ ê³¼ì •ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤.',
        },
        {
            "title": 'ê°œì¸ ê¸°ìˆ  ë¸”ë¡œê·¸ ê°œë°œ',
            "description": 'Django í”„ë ˆì„ì›Œí¬ë¥¼ ì´ìš©í•´ ê°œì¸ ê¸°ìˆ  ë¸”ë¡œê·¸ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. CRUD ê¸°ëŠ¥ê³¼ íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ ê¸°ëŠ¥ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.',
        },
        {
            "title": 'ì‚¬ë‚´ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•',
            "description": 'Tableauì™€ SQLì„ í™œìš©í•˜ì—¬ ë§ˆì¼€íŒ… íŒ€ì˜ KPIë¥¼ ì¶”ì í•˜ëŠ” ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì¶•í•˜ì—¬ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í–ˆìŠµë‹ˆë‹¤.',
        }
    ]
}

# 2. Perplexity API í˜¸ì¶œ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
DUMMY_ANALYSIS_RESULTS = {
    "ì‚¼ì„±ì „ì": {
        "summary": "AIê°€ ë¶„ì„í•œ 'ì‚¼ì„±ì „ì'ì˜ ìµœê·¼ í•µì‹¬ í‚¤ì›Œë“œëŠ” **'ì´ˆê±°ëŒ€ AI', 'LLM ê²½ëŸ‰í™”', 'HBM ë°˜ë„ì²´'** ì…ë‹ˆë‹¤. íŠ¹íˆ AI ë°˜ë„ì²´ ë¶€ë¬¸ì—ì„œì˜ ë¦¬ë”ì‹­ í™•ë³´ë¥¼ ìœ„í•´ ê³µê²©ì ì¸ R&D íˆ¬ìë¥¼ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ '{job}' ì§ë¬´ì—ì„œëŠ” ê´€ë ¨ ê¸°ìˆ  ê²½í—˜ê³¼ ë°˜ë„ì²´ ì‚°ì—…ì— ëŒ€í•œ ì´í•´ë„ë¥¼ í•¨ê»˜ ì–´í•„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
    },
    "ë„¤ì´ë²„": {
        "summary": "AIê°€ ë¶„ì„í•œ 'ë„¤ì´ë²„'ì˜ ìµœê·¼ í•µì‹¬ í‚¤ì›Œë“œëŠ” **'í•˜ì´í¼í´ë¡œë°”X', 'ìƒì„±í˜• AI', 'B2B ì†”ë£¨ì…˜'** ì…ë‹ˆë‹¤. ìì²´ ê°œë°œí•œ ì´ˆê±°ëŒ€ AI ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ì— ìƒì„±í˜• AIë¥¼ ì ‘ëª©í•˜ê³  ìˆìœ¼ë©°, í´ë¼ìš°ë“œ í”Œë«í¼ì„ í†µí•œ B2B ì‚¬ì—… í™•ì¥ì— ì£¼ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. '{job}' ì§ë¬´ì—ì„œëŠ” ì„œë¹„ìŠ¤ ì¤‘ì‹¬ì˜ AI ëª¨ë¸ ì ìš© ëŠ¥ë ¥ì„ ê°•ì¡°í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤."
    },
    "ì¹´ì¹´ì˜¤": {
        "summary": "AIê°€ ë¶„ì„í•œ 'ì¹´ì¹´ì˜¤'ì˜ ìµœê·¼ í•µì‹¬ í‚¤ì›Œë“œëŠ” **'KoGPT', 'AI ì—ì´ì „íŠ¸', 'ì¹´ì¹´ì˜¤í†¡ ì—°ê³„'** ì…ë‹ˆë‹¤. êµ­ë¯¼ ë©”ì‹ ì € ì¹´ì¹´ì˜¤í†¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ AI ì„œë¹„ìŠ¤ í†µí•©ì— ì§‘ì¤‘í•˜ê³  ìˆìœ¼ë©°, ì‚¬ìš©ì ì¹œí™”ì ì¸ AI ê²½í—˜ ì œê³µì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. '{job}' ì§ë¬´ì—ì„œëŠ” í”Œë«í¼ ìƒíƒœê³„ì— ëŒ€í•œ ì´í•´ì™€ ì°½ì˜ì ì¸ AI ì„œë¹„ìŠ¤ ê¸°íš ì—­ëŸ‰ì„ ì–´í•„í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
    }
}


# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'page' not in st.session_state:
    st.session_state.page = 'main'
if 'company' not in st.session_state:
    st.session_state.company = ''
if 'job' not in st.session_state:
    st.session_state.job = ''

# --- í•¨ìˆ˜ ì •ì˜ ---

def fetch_company_analysis(company, job):
    """Perplexity API í˜¸ì¶œì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í•¨ìˆ˜"""
    st.toast(f"'{company}' ì •ë³´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    time.sleep(1.5) # ì‹¤ì œ API í˜¸ì¶œ ì‹œê°„ì²˜ëŸ¼ ë³´ì´ê²Œ ë”œë ˆì´
    
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ íšŒì‚¬ ì´ë¦„ê³¼ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì˜ í‚¤ë¥¼ ë¹„êµ
    # (ë„ì–´ì“°ê¸°, ëŒ€ì†Œë¬¸ì ë“± ì°¨ì´ë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ì •ê·œí™”)
    normalized_company = company.strip().lower().replace(" ", "")
    
    for key, value in DUMMY_ANALYSIS_RESULTS.items():
        normalized_key = key.strip().lower().replace(" ", "")
        if normalized_company == normalized_key:
            # {job} ë¶€ë¶„ì„ ì‹¤ì œ ì§ë¬´ëª…ìœ¼ë¡œ êµì²´í•˜ì—¬ ë°˜í™˜
            return value["summary"].format(job=job)
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ì— ì—†ëŠ” íšŒì‚¬ì¼ ê²½ìš°, ì¼ë°˜ì ì¸ ì‘ë‹µ ë°˜í™˜
    return f"AIê°€ ë¶„ì„í•œ '{company}'ì˜ ìµœê·¼ í•µì‹¬ í‚¤ì›Œë“œëŠ” **'ë””ì§€í„¸ ì „í™˜', 'ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •', 'ê³ ê° ê²½í—˜ í–¥ìƒ'** ì…ë‹ˆë‹¤. ë”°ë¼ì„œ '{job}' ì§ë¬´ì—ì„œëŠ” ê´€ë ¨ ê¸°ìˆ  ê²½í—˜ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ë„ë¥¼ í•¨ê»˜ ì–´í•„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."


def render_main_page():
    """ë©”ì¸ í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜"""
    st.markdown("<h1 style='text-align: center;'>AutoFolio</h1>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center; color: #5A67D8;'>AIê°€ ë‹¹ì‹ ì˜ ê²½í—˜ì„ ê¸°ì—…ì— ë§ì¶° ì¬êµ¬ì„±í•©ë‹ˆë‹¤</h3>", unsafe_allow_html=True)
    
    st.write("")
    st.write("")

    with st.form("input_form"):
        company = st.text_input("**ì§€ì› íšŒì‚¬ëª…**", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, ë„¤ì´ë²„, ì¹´ì¹´ì˜¤")
        job = st.text_input("**ì§€ì› ì§ë¬´**", placeholder="ì˜ˆ: AI ì—°êµ¬ì›")
        
        submitted = st.form_submit_button("âœ¨ AI ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±í•˜ê¸°")

        if submitted:
            if not company or not job:
                st.error("íšŒì‚¬ëª…ê³¼ ì§ë¬´ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.company = company
                st.session_state.job = job
                st.session_state.page = 'loading'
                st.rerun()

def render_loading_page():
    """ë¡œë”© í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•˜ê³  ê²°ê³¼ í˜ì´ì§€ë¡œ ì „í™˜í•˜ëŠ” í•¨ìˆ˜"""
    company = st.session_state.company
    
    st.markdown("---")
    messages = [
        f"**1/4 ë‹¨ê³„:** '{company}'ì˜ ìµœì‹  ë‰´ìŠ¤ ë° ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (Perplexity API)",
        f"**2/4 ë‹¨ê³„:** ì§ë¬´ì˜ í•µì‹¬ ìš”êµ¬ ì—­ëŸ‰ì„ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤... (GPT-4)",
        f"**3/4 ë‹¨ê³„:** ë‚´ ê²½í—˜ ë°ì´í„°ì™€ ê¸°ì—…ì˜ ìš”êµ¬ ì—­ëŸ‰ì„ ë§¤ì¹­í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
        f"**4/4 ë‹¨ê³„:** AIê°€ ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆì•ˆì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (Gemini)",
        "**ë¶„ì„ ì™„ë£Œ!** ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    ]

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, message in enumerate(messages):
        progress_bar.progress((i + 1) * (100 // len(messages)))
        status_text.info(message)
        time.sleep(1.5)

    st.session_state.page = 'result'
    st.rerun()

def render_result_page():
    """ê²°ê³¼ í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•˜ëŠ” í•¨ìˆ˜"""
    company = st.session_state.company
    job = st.session_state.job
    
    st.markdown(f"## âœ¨ **{company}** ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤")
    st.markdown(f"AIê°€ **'{job}'** ì§ë¬´ì— ë§ì¶° ì¬êµ¬ì„±í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
    st.markdown("---")

    # 1. AI ê¸°ì—… ë¶„ì„ ìš”ì•½ (Perplexity API ì‹œë®¬ë ˆì´ì…˜)
    st.subheader("1. AI ê¸°ì—… ë¶„ì„ ë° ì „ëµ ì œì•ˆ")
    with st.spinner("Perplexity APIë¡œ ìµœì‹  ê¸°ì—… ë™í–¥ì„ ë¶„ì„ ì¤‘..."):
        analysis_result = fetch_company_analysis(company, job)
    st.info(analysis_result)
    st.write("")
    
    # 2. ë§ì¶¤ ìê¸°ì†Œê°œ ìš”ì•½
    st.subheader("2. AI ìê¸°ì†Œê°œì„œ ì´ˆì•ˆ (Profile Summary)")
    st.success(f"""
    '{job}' ì§ë¬´ì— ëŒ€í•œ ê¹Šì€ ì´í•´ì™€ **LLM, PyTorch** ì—­ëŸ‰ì„ ë°”íƒ•ìœ¼ë¡œ, '{company}'ê°€ ì¶”êµ¬í•˜ëŠ” ì°¨ì„¸ëŒ€ AI ê¸°ìˆ  ê°œë°œì— ê¸°ì—¬í•  ì¤€ë¹„ê°€ ëœ ì¸ì¬ì…ë‹ˆë‹¤. 
    íŠ¹íˆ **ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ ê²½ëŸ‰í™”** ê²½í—˜ì€ ê·€ì‚¬ì˜ ê²½ìŸë ¥ ê°•í™”ì— ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.
    """)
    st.write("")

    # 3. ì—­ëŸ‰ ë¶„ì„ (Skill Match)
    st.subheader("3. í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Skill Match)")
    required_skills = ['LLM', 'PyTorch', 'TensorFlow', 'SQL']
    match_count = len(set(DUMMY_USER_PROFILE['skills']) & set(required_skills))
    
    col1, col2 = st.columns(2)
    col1.metric(label="ë‚˜ì˜ ë³´ìœ  ì—­ëŸ‰", value=f"{len(DUMMY_USER_PROFILE['skills'])} ê°œ")
    col2.metric(label=f"'{job}' í•µì‹¬ ìš”êµ¬ ì—­ëŸ‰", value=f"{len(required_skills)} ê°œ", delta=f"{match_count} ê°œ ì¼ì¹˜")

    skill_data = {"skill": [], "match": []}
    for skill in DUMMY_USER_PROFILE['skills']:
        skill_data["skill"].append(skill)
        skill_data["match"].append(1 if skill in required_skills else 0.5)
        
    df = pd.DataFrame(skill_data)
    st.write("**ì—­ëŸ‰ ì¼ì¹˜ë„ ì‹œê°í™” (Gemini)**")
    st.bar_chart(df.set_index('skill')['match'])
    st.caption("AIê°€ ë¶„ì„í•œ í•µì‹¬ ìš”êµ¬ ì—­ëŸ‰ê³¼ ì¼ì¹˜í•˜ëŠ” ìŠ¤í‚¬ì´ ë” ë†’ê²Œ í‘œì‹œë©ë‹ˆë‹¤.")
    st.write("")

    # 4. í”„ë¡œì íŠ¸ ì¬ë°°ì¹˜ ë° ì„¤ëª… ìˆ˜ì •
    st.subheader("4. AI ì¶”ì²œ í”„ë¡œì íŠ¸ ë° ì„¤ëª… ì¬êµ¬ì„±")
    st.warning("AIê°€ ì§ë¬´ ì—°ê´€ì„±ì´ ê°€ì¥ ë†’ë‹¤ê³  íŒë‹¨í•œ í”„ë¡œì íŠ¸ë¥¼ **ìƒë‹¨ì— ì¬ë°°ì¹˜**í–ˆìŠµë‹ˆë‹¤.")
    
    first_project = DUMMY_USER_PROFILE['projects'][0]
    with st.expander(f"**ğŸ† {first_project['title']} (AI ì¶”ì²œ)**", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ê¸°ì¡´ ì„¤ëª…**")
            st.markdown(f"<div style='background-color:#f0f2f6; padding:10px; border-radius:5px;'>{first_project['description']}</div>", unsafe_allow_html=True)
        with col2:
            st.markdown("**AI ì¬êµ¬ì„± ì„¤ëª… (GPT-4)**")
            rewritten_desc = f"'{company}'ì˜ ì‚¬ìš©ì ì¤‘ì‹¬ AI ê²½í—˜ ì „ëµì— ë°œë§ì¶°, **LSTM ê¸°ë°˜ ê°ì„± ë¶„ì„ ëª¨ë¸**ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” **ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬** ëŠ¥ë ¥ê³¼ **PyTorchë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ìµœì í™”** ì—­ëŸ‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
            st.markdown(f"<div style='background-color:#d4edda; padding:10px; border-radius:5px;'>{rewritten_desc}</div>", unsafe_allow_html=True)
            
    for project in DUMMY_USER_PROFILE['projects'][1:]:
        with st.expander(f"**ğŸ“„ {project['title']}**"):
            st.write(project['description'])
            
    st.markdown("---")
    
    # 5. ë‹¤ìš´ë¡œë“œ ë° ì¬ì‹œì‘
    st.subheader("í¬íŠ¸í´ë¦¬ì˜¤ í™œìš©í•˜ê¸°")
    report_text = f"# {company} ë§ì¶¤ í¬íŠ¸í´ë¦¬ì˜¤ ({job})\n\n(ìƒì„±ëœ ë‚´ìš© ìš”ì•½...)"
    st.download_button(
        label="ğŸ“„ í¬íŠ¸í´ë¦¬ì˜¤ í…ìŠ¤íŠ¸ë¡œ ë‹¤ìš´ë¡œë“œ",
        data=report_text,
        file_name=f"{company}_{job}_portfolio.txt",
    )

    if st.button("ğŸ  ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# --- ë©”ì¸ ë¡œì§ ---
if st.session_state.page == 'main':
    render_main_page()
elif st.session_state.page == 'loading':
    render_loading_page()
elif st.session_state.page == 'result':
    render_result_page()

